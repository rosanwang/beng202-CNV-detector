{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and packages\n",
    "import re\n",
    "\n",
    "match = 2\n",
    "mismatch = 1\n",
    "gap = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GlobalAlignmentBacktrack(v, w, indel, match_reward, mismatch_penalty):\n",
    "    vLen = len(v)\n",
    "    wLen = len(w)\n",
    "    backtrack = [[0] * (vLen + 1) for _ in range(wLen + 1)]\n",
    "    s = [[0] * (vLen + 1) for _ in range(wLen + 1)]\n",
    "\n",
    "    for i in range(1, wLen + 1):\n",
    "        s[i][0] = s[i-1][0] - indel\n",
    "        backtrack[i][0] = \"down\"\n",
    "    for j in range(1, vLen + 1):\n",
    "        s[0][j] = s[0][j-1] - indel\n",
    "        backtrack[0][j] = \"right\"\n",
    "\n",
    "    for i in range(1, wLen + 1):\n",
    "        for j in range(1, vLen + 1):\n",
    "            w_letter = w[i-1]\n",
    "            v_letter = v[j-1]\n",
    "\n",
    "            # determine if match or mismatch\n",
    "            if w_letter == v_letter:\n",
    "                diag = s[i-1][j-1] + match_reward\n",
    "            else:\n",
    "                diag = s[i-1][j-1] - mismatch_penalty\n",
    "\n",
    "            right = s[i][j-1] - indel\n",
    "            down = s[i-1][j] - indel\n",
    "\n",
    "            s[i][j] = max(right, down, diag)\n",
    "\n",
    "            if s[i][j] == down:\n",
    "                backtrack[i][j] = \"down\"\n",
    "            elif s[i][j] == right:\n",
    "                backtrack[i][j] = \"right\"\n",
    "            elif s[i][j] ==  diag:\n",
    "                backtrack[i][j] = \"diagonal\"\n",
    "\n",
    "    return backtrack, s\n",
    "\n",
    "def OutputGlobalAlignment(Backtrack, str2, str1):\n",
    "    align1 = \"\"\n",
    "    align2 = \"\"\n",
    "    i = len(str2)\n",
    "    j = len(str1)\n",
    "\n",
    "    while not(i == 0 and j == 0):\n",
    "        if Backtrack[i][j] == \"down\": # insertion in string 1 \n",
    "            i = i-1\n",
    "            align2 = str2[i] + align2\n",
    "            align1 = \"-\" + align1\n",
    "\n",
    "        elif Backtrack[i][j] == \"right\": # deletion in string 1 \n",
    "            j = j-1\n",
    "            align2 = \"-\" + align2\n",
    "            align1 = str1[j] + align1\n",
    "        else:\n",
    "            i = i-1\n",
    "            j = j-1\n",
    "            align2 = str2[i] + align2\n",
    "            align1 = str1[j] + align1\n",
    "\n",
    "    return align1, align2\n",
    "\n",
    "# match_reward=match, mismatch_penalty=mismatch, indel_penalty=gap\n",
    "def global_alignment( s: str, t: str, match_reward=match, mismatch_penalty=mismatch, indel_penalty=gap):\n",
    "        backtrack, score = GlobalAlignmentBacktrack(s, t, indel_penalty, match_reward, mismatch_penalty)\n",
    "        alignments = OutputGlobalAlignment(backtrack, t, s)\n",
    "        return score[len(t)][len(s)], alignments[0], alignments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: splits s and t after common subsequence alignment\n",
    "def split_string(s, t, string):\n",
    "\n",
    "    s_idx = s.find(string)\n",
    "    t_idx = t.find(string)\n",
    "\n",
    "    # Extract left and right parts\n",
    "    s_left, s_right = s[:s_idx], s[s_idx + len(string):]\n",
    "    t_left, t_right = t[:t_idx], t[t_idx + len(string):]\n",
    "\n",
    "    return s_left, s_right, t_left, t_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: find optimal common shared subsequence\n",
    "# premise \n",
    "#   uni-alignments are more evolutionarily relevant\n",
    "#   longer substrings tend to be evolutionarily conserved  \n",
    "\n",
    "\"\"\"\n",
    "    lcp_array(comb, suffix_a)\n",
    "    generates the lcp array\n",
    "\n",
    "    Args:\n",
    "        comb (str): combination of both strings with \"$\" appended to the  (s + \"$\" + t + \"#\")\n",
    "        suffix_a (array): suffix array \n",
    "\n",
    "        suffix array \n",
    "        - all the suffixes in sorted order with the index in which they occur \n",
    "\n",
    "    Returns:\n",
    "        array: the lcp array \n",
    "\"\"\"\n",
    "\n",
    "def lcp_array(comb, suffix_a):\n",
    "    # constructs an lcp array\n",
    "    rank = [0] * len(comb)\n",
    "    lcp = [0] * len(comb)\n",
    "    \n",
    "    for i, suffix in enumerate(suffix_a):\n",
    "        rank[suffix] = i\n",
    "    \n",
    "    idx = 0\n",
    "    for i in range(len(comb)):\n",
    "        if rank[i] > 0:\n",
    "            j = suffix_a[rank[i] - 1]\n",
    "            while (i + idx < len(comb)) and (j + idx < len(comb)) and (comb[i + idx] == comb[j + idx]):\n",
    "                idx += 1\n",
    "            lcp[rank[i]] = idx\n",
    "            if idx > 0:\n",
    "                idx -= 1\n",
    "    return lcp\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    function:\n",
    "    finding thing optimal common shared subsequence \n",
    "    only returns one substring \n",
    "\n",
    "    Args:\n",
    "        s: string S \n",
    "        t: string T\n",
    "        k1: int (such that k1 < k2 -- see tandem_transform_lcs)\n",
    "    \n",
    "    Returns: \n",
    "        longest: string \n",
    "        the longest common subsequence between strings S and T. \n",
    "        if there are two longest common subsequences of the same length, \n",
    "            return the one which maximizes the global alignment score.\n",
    "        \n",
    "        our code breaks if there are no matches between S and T \n",
    "        \n",
    "\"\"\"\n",
    "def lus(s, t, k1):\n",
    "    # find longest unique substrings between s and t\n",
    "    comb = s + \"$\" + t + \"#\"\n",
    "\n",
    "    # craete suffix array\n",
    "    suffixes = [(comb[i:], i) for i in range(len(comb))]\n",
    "    suffixes.sort()\n",
    "    suffix_array = [suffix[1] for suffix in suffixes]\n",
    "    \n",
    "    # create lcp array\n",
    "    lcp = lcp_array(comb, suffix_array)\n",
    "    \n",
    "    # find all unique substrings\n",
    "    all_shared_substrings = []\n",
    "\n",
    "    for i in range(1, len(comb)):\n",
    "        suff_one = suffix_array[i]\n",
    "        suff_two = suffix_array[i - 1]\n",
    "\n",
    "        if (suff_one < len(s) and suff_two > len(s)) or (suff_one > len(s) and suff_two < len(s)):\n",
    "            if lcp[i] > 0:\n",
    "                if (i-1) >= 0:\n",
    "                     prev = lcp[i - 1] \n",
    "                else:\n",
    "                     prev = 0\n",
    "                if (i+1) < len(lcp):\n",
    "                     next = lcp[i+1]\n",
    "                else:\n",
    "                     next = 0\n",
    "\n",
    "                if lcp[i] > max(prev, next):\n",
    "                    shared = comb[suff_one : suff_one + lcp[i]]\n",
    "                    all_shared_substrings.append(shared)\n",
    "    \n",
    "    # find longest string with most optimal score\n",
    "    max_len = 0\n",
    "    for string in all_shared_substrings:\n",
    "        max_len = max(len(string), max_len)\n",
    "\n",
    "    longest = None\n",
    "    cur_score = float(\"-inf\")\n",
    "\n",
    "    for string in all_shared_substrings:\n",
    "        if len(string) == max_len and len(string) > k1:\n",
    "            sl, sr, tl, tr = split_string(s, t, string)\n",
    "            score = global_alignment(sl, tl)[0] + global_alignment(sr, tr)[0]\n",
    "            if score > cur_score:\n",
    "                longest = string\n",
    "    return longest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: determine search space\n",
    "# all kmers in left or right edge of alignment that can lead to tandem duplication / deletion\n",
    "def get_search_space_right(s_sub, t_sub, k1, k2, common_alignment):\n",
    "\n",
    "    temp = []\n",
    "    for i in range(k1, k2+1):\n",
    "        temp.append(common_alignment[len(common_alignment) - i:])\n",
    "\n",
    "    search_space = []\n",
    "    for kmer in temp:\n",
    "        # tandem deletion\n",
    "        kmer = kmer.replace(\" \", \"\")\n",
    "\n",
    "        if s_sub[:len(kmer)] == kmer and t_sub[:len(kmer)] != kmer:\n",
    "            search_space.append((kmer, 'del'))\n",
    "\n",
    "        # tandem duplication\n",
    "        if s_sub[:len(kmer)] != kmer and t_sub[:len(kmer)] == kmer:\n",
    "            search_space.append((kmer, 'dup'))\n",
    "\n",
    "    return search_space\n",
    "\n",
    "def get_search_space_left(s_sub, t_sub, k1, k2, common_alignment):\n",
    "\n",
    "    temp = []\n",
    "    for i in range(k1, k2+1):\n",
    "        temp.append(common_alignment[:i])\n",
    "\n",
    "    search_space = []\n",
    "    for kmer in temp:\n",
    "        # tandem deletion\n",
    "        kmer = kmer.replace(\" \", \"\")\n",
    "\n",
    "        if s_sub[len(common_alignment) - len(kmer) - 1:] == kmer and t_sub[len(common_alignment) - len(kmer) - 1:] != kmer:\n",
    "            search_space.append((kmer, 'del'))\n",
    "\n",
    "        # tandem duplication\n",
    "        if s_sub[len(common_alignment) - len(kmer) - 1:] != kmer and t_sub[len(common_alignment) - len(kmer) - 1:] == kmer:\n",
    "            search_space.append((kmer, 'dup'))\n",
    "\n",
    "    return search_space\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tandem_transform_lcs(s: str, t: str, k1: int, k2: int, v: int):\n",
    "        # keep track of kmers\n",
    "        kmers = []\n",
    "        max_iters = 100\n",
    "        iters = 0\n",
    "\n",
    "        # This while loop ensures that all potential tandem transformations around alignment are explored\n",
    "        while iters < max_iters:\n",
    "\n",
    "                score = global_alignment(s, t)\n",
    "                if score[0] >= v:\n",
    "                        if iters == 0:\n",
    "                                print(\"Strings similar enough.\")\n",
    "                        return (score[0], score[1], score[2], kmers)\n",
    "\n",
    "                # find best possible alignment between s and t longer than k1, uses greedy approach\n",
    "                common_alignment = lus(s, t, k1)\n",
    "\n",
    "                # return if no common alignments exist\n",
    "                if not common_alignment:\n",
    "                        return (score[0], score[1], score[2], kmers)\n",
    "                \n",
    "                indices = [(x.start(), x.end() - 1) for x in re.finditer(re.escape(common_alignment), s)][0]\n",
    "\n",
    "        \n",
    "                # align s and t to common prefix, get the left flanking and right flanking sequence\n",
    "                sl, sr, tl, tr = split_string(s, t, common_alignment)\n",
    "\n",
    "                # left side applied transformations\n",
    "\n",
    "                # left kmer search space\n",
    "                search_space_l = get_search_space_left(sl, tl, k1, k2, common_alignment)\n",
    "\n",
    "                # test left side search space values and find the one that leads to highest global alignment score when applied\n",
    "                max_score = float(\"-inf\")\n",
    "                transformation = \"\"\n",
    "                for transforms in search_space_l:\n",
    "                        if transforms[-1] == \"del\":\n",
    "                                s_trans = sl[:len(sl) - len(transforms[0])]\n",
    "                        else:\n",
    "                                s_trans = sl + transforms[0]\n",
    "                        reconstructed = s_trans + common_alignment  + s[indices[-1] + 1:]\n",
    "\n",
    "                        # apply transformation and check alignment score\n",
    "                        score = global_alignment(reconstructed, t)\n",
    "\n",
    "                        if score[0] > v:\n",
    "                                # if threshold is reached, a tandem transformation has been found\n",
    "                                kmers.append(transforms)\n",
    "                                return (score[0], score[1], score[2], kmers)\n",
    "                        else:\n",
    "                                # assign the highest scoring transformation \n",
    "                                if score[0] > max_score:\n",
    "                                        transformation = reconstructed\n",
    "                                        target_kmer = transforms\n",
    "\n",
    "                # right kmer search space\n",
    "                if search_space_l:\n",
    "                        s = transformation\n",
    "                        kmers.append(target_kmer)\n",
    "                indices = [(x.start(), x.end() - 1) for x in re.finditer(re.escape(common_alignment), s)][0]\n",
    "                search_space_r = get_search_space_right(sr, tr, k1, k2, common_alignment)\n",
    "\n",
    "\n",
    "                # test right side search space values and select the one that leads to highest global alignment score when applied\n",
    "                transformation_r = \"\"\n",
    "                for transforms in search_space_r:\n",
    "\n",
    "                        if transforms[-1] == \"del\":\n",
    "                                s_trans = sr[len(transforms[0]):]\n",
    "                        else:\n",
    "                                s_trans = transforms[0] + sr\n",
    "        \n",
    "                        reconstructed = s[:indices[-1] + 1] + s_trans\n",
    "\n",
    "                        # apply transformation and check alignment score\n",
    "                        # score = similarity(reconstructed, t)\n",
    "                        score = global_alignment(reconstructed, t)\n",
    "\n",
    "                        if score[0] > v:\n",
    "                                # if threshold is reached, a tandem transformation has been found\n",
    "                                kmers.append(transforms)\n",
    "                                return (score[0], score[1], score[2], kmers)\n",
    "                        else:\n",
    "                                # assign the highest scoring transformation \n",
    "                                if score[0] > max_score:\n",
    "                                        transformation_r = reconstructed\n",
    "                                        target_kmer = transforms\n",
    "\n",
    "                # transformation on right side complete, final s transformation for this iteration\n",
    "                if search_space_r:\n",
    "                        s = transformation_r\n",
    "                        kmers.append(target_kmer)\n",
    "\n",
    "                # no more possible tandem duplications or deletions\n",
    "                if not search_space_l and not search_space_r:\n",
    "                        print(\"All tandem transformations exhausted for this alignment.\")\n",
    "                        return (score[0], score[1], score[2], kmers)\n",
    "                \n",
    "                iters += 1\n",
    "                \n",
    "        return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Tandem Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tandem transformations exhausted for this alignment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 'TACCATC--', '-ACCATCTT', [('ATC', 'del')])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic test case to ensure proper alignment and detection of deletion\n",
    "tandem_transform_lcs(\"TACCATCATC\",\n",
    "                     \"ACCATCTT\",\n",
    "                     2,\n",
    "                     3,\n",
    "                     15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tandem transformations exhausted for this alignment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-4,\n",
       " '------AGACAC',\n",
       " 'CTTCTTAGACA-',\n",
       " [('CA', 'del'),\n",
       "  ('CA', 'del'),\n",
       "  ('CA', 'del'),\n",
       "  ('CA', 'del'),\n",
       "  ('CA', 'del'),\n",
       "  ('CA', 'del')])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This test case accounts for repeated tandem duplications\n",
    "tandem_transform_lcs(\"AGACACACACACACACAC\",\n",
    "                     \"CTTCTTAGACA\",\n",
    "                     2,\n",
    "                     3,\n",
    "                     3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 'CCTAACTCTCTA', 'CCTAACTCTCTA', [('AA', 'del'), ('CT', 'dup')])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This test case accounts for same length string and similar alignment reached before all possible options exhausted\n",
    "tandem_transform_lcs(\"CCTAAAACTCTA\",\n",
    "                     \"CCTAACTCTCTA\",\n",
    "                     2,\n",
    "                     3,\n",
    "                     20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
