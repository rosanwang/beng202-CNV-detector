{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and packages\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "match = 2\n",
    "mismatch = -1\n",
    "gap = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: global alignment for similarity score\n",
    "\n",
    "def lcs_backtrack(v, w, match, mismatch, indel):\n",
    "    s = []\n",
    "    for _ in range(len(v) + 1):\n",
    "        s.append([0] * (len(w) + 1))\n",
    "\n",
    "    temp = [0]\n",
    "    for i in range(len(s[0])-1):\n",
    "        val = temp[i] - indel\n",
    "        temp.append(val)\n",
    "    s[0] = temp\n",
    "\n",
    "    for i in range(1, len(s)):\n",
    "        val = s[i-1][0] - indel\n",
    "        s[i][0] = val\n",
    "\n",
    "    for i in range(1, len(v) + 1):\n",
    "        for j in range(1, len(w) + 1):\n",
    "            m = 0\n",
    "            if v[i-1] == w[j-1]:\n",
    "                m = match\n",
    "            else:\n",
    "                m = -(mismatch)\n",
    "            s[i][j] = max(s[i-1][j] - indel, s[i][j-1] - indel, s[i-1][j-1] + m)\n",
    "    return s\n",
    "\n",
    "# Insert your global_alignment function here, along with any subroutines you need\n",
    "def similarity(s, t, match_reward=match, mismatch_penalty=mismatch, indel_penalty=gap):\n",
    "    manhatten = lcs_backtrack(s, t, match_reward, mismatch_penalty, indel_penalty)\n",
    "    score = manhatten[-1][-1]\n",
    "\n",
    "    i = len(s)\n",
    "    j = len(t)\n",
    "    s1 = \"\"\n",
    "    s2 = \"\"\n",
    "    while i != 0 and j != 0:\n",
    "        if manhatten[i][j-1] - indel_penalty == manhatten[i][j]:\n",
    "            s1 += \"-\"\n",
    "            j -= 1\n",
    "            s2 += t[-1]\n",
    "            t = t[:-1]\n",
    "        elif manhatten[i-1][j] - indel_penalty == manhatten[i][j]:\n",
    "            s1 += s[-1]\n",
    "            s = s[:-1]\n",
    "            s2 += \"-\"\n",
    "            i -= 1\n",
    "        else:\n",
    "            s1 += s[-1]\n",
    "            s = s[:-1]\n",
    "            s2 += t[-1]\n",
    "            t = t[:-1]\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    return score, s1[::-1], s2[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sequence(s, t, lcp):\n",
    "    score = 0\n",
    "    # take substrings of s and t to left of lcp, calculate global alignment\n",
    "\n",
    "    # take substrings of s and t to right of lcp, calculate global alignment\n",
    "\n",
    "    # return sum of these scores\n",
    "\n",
    "    return score\n",
    "\n",
    "def lcp_align(s, t):\n",
    "    # use lcp array to find longest possible common prefixes and calculate score\n",
    "    lcps = []\n",
    "    max_score = float(\"-inf\")\n",
    "    cur_lcp = None\n",
    "    for lcp in lcps:\n",
    "        # find maximum score\n",
    "        score = score_sequence(s, t, lcp)\n",
    "        if score > max_score:\n",
    "            cur_lcp = lcp\n",
    "    return cur_lcp\n",
    "\n",
    "\n",
    "def score_transformation(s, t, kmer):\n",
    "    # use global alignment to score the tandem kmer duplication or deletion\n",
    "\n",
    "\n",
    "def tandem_transform_lcs(s: str, t: str, k1: int, k2: int, v: int):\n",
    "\n",
    "    def divide_and_conquer(s, t, k1, k2, v, start, end):\n",
    "\n",
    "        # find best possible lcp alignement of strings s and t\n",
    "        common_prefix = lcp_align(s, t)\n",
    "\n",
    "        # align s and t to common prefix, get the left flanking and right flanking sequence\n",
    "\n",
    "        # determine search space (all kmers in left or right edge of alignment that can lead to tandem duplication / deletion)\n",
    "            # # find if there is a tandem duplication and deletion with that respective kmer, if so, it'll be in the search space\n",
    "\n",
    "        # test all search space values and select the one that leads to highest global alignment score when applied\n",
    "\n",
    "        # apply transformation\n",
    "\n",
    "        # similarity score it with ENTIRE s and t string. if pass threshold with global alignemnt, dn this and return s and t transformed\n",
    "\n",
    "        # if not, apply transformation to s\n",
    "\n",
    "        # do this recursively with remaining sequence that is before transformation site, if left flanking as well as reamining sequence that is after the transformation site\n",
    "\n",
    "    \n",
    "    # you shoudl have a fully transformed tandem s string that when aligned with t, will produce a similarity score above the trheshold v\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def exhaustive_search(kmers, transforms):\n",
    "    # find all possible combinations of tandem duplications / deletions given set of kmers\n",
    "\n",
    "    dups = [(kmer[0], kmer[1], \"dup\") for kmer in kmers]\n",
    "    dels = [(kmer[0], kmer[1], \"del\") for kmer in kmers]\n",
    "\n",
    "    return list(itertools.product(dups+dels, repeat=transforms))\n",
    "\n",
    "# add string duplication\n",
    "def duplicate(s, dupl):\n",
    "    start = dupl[0]\n",
    "    insert = dupl[1]\n",
    "    k = len(dupl)\n",
    "\n",
    "    # insert duplication at next spot that doesn't contain target kmer\n",
    "    not_inserted = True\n",
    "    while not_inserted:\n",
    "        if s[start:start+k] == insert:\n",
    "            start += k\n",
    "        else:\n",
    "            s = s[:start] + insert + s[start:]\n",
    "            not_inserted = False\n",
    "    return s\n",
    "\n",
    "# do tandem string deletion\n",
    "# def delete(s, delete):\n",
    "\n",
    "\n",
    "# find tandem transformations\n",
    "# minimize umber of transforms from s to t\n",
    "\n",
    "def find_tandem_transformation(s: str, t: str, k1: int, k2: int, v: int):\n",
    "\n",
    "    # find all possible kmers between lengths k1 and k2 in S\n",
    "    all_kmers = set()\n",
    "    for k_len in range(k1,k2+1):\n",
    "        for i in range(0, len(s)-k_len + 1):\n",
    "            all_kmers.add((i, s[i:i+k_len]))\n",
    "    \n",
    "    # find all possible events\n",
    "    # assume maximum number of tandem transforms is five, can be adjusted\n",
    "    t = 5\n",
    "    for i in range(2, t):\n",
    "        all_combos = exhaustive_search(all_kmers, i)\n",
    "        \n",
    "        # iterate through all possible combinations\n",
    "        for comb in all_combos:\n",
    "            transformed_s = s\n",
    "\n",
    "            # keep track of duplicated transformations\n",
    "            duplicated = set()\n",
    "\n",
    "            print(comb)\n",
    "\n",
    "            # apply transformations to string\n",
    "            for transforms in comb:\n",
    "                if transforms[-1] == 'dup':\n",
    "                    transformed_s = duplicate(transformed_s, transforms)\n",
    "                    duplicated.add(())\n",
    "            print(transformed_s)\n",
    "            \n",
    "            print()\n",
    "\n",
    "            break\n",
    "    # remove any value that has a duplication and deletion in same spot\n",
    "    # if there's repeated deletions that will destroy teh sequence, bypass this combination too2\n",
    "\n",
    "\n",
    "find_tandem_transformation(\"ABC\", \"ABABAB\", 2, 3, 5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
