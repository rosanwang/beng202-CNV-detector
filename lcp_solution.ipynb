{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and packages\n",
    "match = 2\n",
    "mismatch = -1\n",
    "gap = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: global alignment for similarity score\n",
    "\n",
    "def lcs_backtrack(v, w, match, mismatch, indel):\n",
    "\n",
    "    s = []\n",
    "    for _ in range(len(v) + 1):\n",
    "        s.append([0] * (len(w) + 1))\n",
    "\n",
    "    temp = [0]\n",
    "    for i in range(len(s[0])-1):\n",
    "        val = temp[i] - indel\n",
    "        temp.append(val)\n",
    "    s[0] = temp\n",
    "\n",
    "    for i in range(1, len(s)):\n",
    "        val = s[i-1][0] - indel\n",
    "        s[i][0] = val\n",
    "\n",
    "    for i in range(1, len(v) + 1):\n",
    "        for j in range(1, len(w) + 1):\n",
    "            m = 0\n",
    "            if v[i-1] == w[j-1]:\n",
    "                m = match\n",
    "            else:\n",
    "                m = -(mismatch)\n",
    "            s[i][j] = max(s[i-1][j] - indel, s[i][j-1] - indel, s[i-1][j-1] + m)\n",
    "    return s\n",
    "\n",
    "# Insert your global_alignment function here, along with any subroutines you need\n",
    "def similarity(s, t, match_reward=match, mismatch_penalty=mismatch, indel_penalty=gap):\n",
    "    manhatten = lcs_backtrack(s, t, match_reward, mismatch_penalty, indel_penalty)\n",
    "    score = manhatten[-1][-1]\n",
    "\n",
    "    i = len(s)\n",
    "    j = len(t)\n",
    "    s1 = \"\"\n",
    "    s2 = \"\"\n",
    "    while i != 0 and j != 0:\n",
    "        if manhatten[i][j-1] - indel_penalty == manhatten[i][j]:\n",
    "            s1 += \"-\"\n",
    "            j -= 1\n",
    "            s2 += t[-1]\n",
    "            t = t[:-1]\n",
    "        elif manhatten[i-1][j] - indel_penalty == manhatten[i][j]:\n",
    "            s1 += s[-1]\n",
    "            s = s[:-1]\n",
    "            s2 += \"-\"\n",
    "            i -= 1\n",
    "        else:\n",
    "            s1 += s[-1]\n",
    "            s = s[:-1]\n",
    "            s2 += t[-1]\n",
    "            t = t[:-1]\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    return score, s1[::-1], s2[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: splits s and t after common subsequence alignment\n",
    "def split_string(s, t, string):\n",
    "\n",
    "    s_idx = s.find(string)\n",
    "    t_idx = t.find(string)\n",
    "\n",
    "    # Extract left and right parts\n",
    "    s_left, s_right = s[:s_idx], s[s_idx + len(string):]\n",
    "    t_left, t_right = t[:t_idx], t[t_idx + len(string):]\n",
    "\n",
    "    return s_left, s_right, t_left, t_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: find optimal common shared subsequence\n",
    "# premise \n",
    "#   uni-alignments are more evolutionarily relevant\n",
    "#   longer substrings tend to be evolutionarily conserved  \n",
    "\n",
    "\"\"\"\n",
    "    lcp_array(comb, suffix_a)\n",
    "    generates the lcp array\n",
    "\n",
    "    Args:\n",
    "        comb (str): combination of both strings with \"$\" appended to the  (s + \"$\" + t + \"#\")\n",
    "        suffix_a (array): suffix array \n",
    "\n",
    "        suffix array \n",
    "        - all the suffixes in sorted order with the index in which they occur \n",
    "\n",
    "    Returns:\n",
    "        array: the lcp array \n",
    "\"\"\"\n",
    "\n",
    "def lcp_array(comb, suffix_a):\n",
    "    # constructs an lcp array\n",
    "    rank = [0] * len(comb)\n",
    "    lcp = [0] * len(comb)\n",
    "    \n",
    "    for i, suffix in enumerate(suffix_a):\n",
    "        rank[suffix] = i\n",
    "    \n",
    "    idx = 0\n",
    "    for i in range(len(comb)):\n",
    "        if rank[i] > 0:\n",
    "            j = suffix_a[rank[i] - 1]\n",
    "            while (i + idx < len(comb)) and (j + idx < len(comb)) and (comb[i + idx] == comb[j + idx]):\n",
    "                idx += 1\n",
    "            lcp[rank[i]] = idx\n",
    "            if idx > 0:\n",
    "                idx -= 1\n",
    "    return lcp\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    function:\n",
    "    finding thing optimal common shared subsequence \n",
    "    only returns one substring \n",
    "\n",
    "    Args:\n",
    "        s: string S \n",
    "        t: string T\n",
    "        k1: int (such that k1 < k2 -- see tandem_transform_lcs)\n",
    "    \n",
    "    Returns: \n",
    "        longest: string \n",
    "        the longest common subsequence between strings S and T. \n",
    "        if there are two longest common subsequences of the same length, \n",
    "            return the one which maximizes the global alignment score.\n",
    "        \n",
    "        our code breaks if there are no matches between S and T \n",
    "        \n",
    "\"\"\"\n",
    "def lus(s, t, k1):\n",
    "    # find longest unique substrings between s and t\n",
    "    comb = s + \"$\" + t + \"#\"\n",
    "\n",
    "    # craete suffix array\n",
    "    suffixes = [(comb[i:], i) for i in range(len(comb))]\n",
    "    suffixes.sort()\n",
    "    suffix_array = [suffix[1] for suffix in suffixes]\n",
    "    \n",
    "    # create lcp array\n",
    "    lcp = lcp_array(comb, suffix_array)\n",
    "    \n",
    "    # find all unique substrings\n",
    "    all_shared_substrings = []\n",
    "\n",
    "    for i in range(1, len(comb)):\n",
    "        suff_one = suffix_array[i]\n",
    "        suff_two = suffix_array[i - 1]\n",
    "\n",
    "        if (suff_one < len(s) and suff_two > len(s)) or (suff_one > len(s) and suff_two < len(s)):\n",
    "            if lcp[i] > 0:\n",
    "                if (i-1) >= 0:\n",
    "                     prev = lcp[i - 1] \n",
    "                else:\n",
    "                     prev = 0\n",
    "                if (i+1) < len(lcp):\n",
    "                     next = lcp[i+1]\n",
    "                else:\n",
    "                     next = 0\n",
    "\n",
    "                if lcp[i] > max(prev, next):\n",
    "                    shared = comb[suff_one : suff_one + lcp[i]]\n",
    "                    all_shared_substrings.append(shared)\n",
    "    \n",
    "    # find longest string with most optimal score\n",
    "    max_len = 0\n",
    "    for string in all_shared_substrings:\n",
    "        max_len = max(len(string), max_len)\n",
    "\n",
    "    longest = None\n",
    "    cur_score = float(\"-inf\")\n",
    "\n",
    "    for string in all_shared_substrings:\n",
    "        if len(string) == max_len and len(string) > k1:\n",
    "            sl, sr, tl, tr = split_string(s, t, string)\n",
    "            score = similarity(sl, tl)[0] + similarity(sr, tr)[0]\n",
    "            if score > cur_score:\n",
    "                longest = string\n",
    "    return longest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: determine search space\n",
    "# all kmers in left or right edge of alignment that can lead to tandem duplication / deletion\n",
    "def get_search_space_right(s_sub, t_sub, k1, k2, common_alignment):\n",
    "\n",
    "    temp = []\n",
    "    for i in range(k1, k2+1):\n",
    "        temp.append(common_alignment[len(common_alignment) - i:])\n",
    "\n",
    "    search_space = []\n",
    "    for kmer in temp:\n",
    "        # tandem deletion\n",
    "        kmer = kmer.replace(\" \", \"\")\n",
    "\n",
    "        if s_sub[:len(kmer)] == kmer and t_sub[:len(kmer)] != kmer:\n",
    "            search_space.append((kmer, 'del'))\n",
    "\n",
    "        # tandem duplication\n",
    "        if s_sub[:len(kmer)] != kmer and t_sub[:len(kmer)] == kmer:\n",
    "            search_space.append((kmer, 'dup'))\n",
    "\n",
    "    return search_space\n",
    "\n",
    "def get_search_space_left(s_sub, t_sub, k1, k2, common_alignment):\n",
    "\n",
    "    search_space = []\n",
    "    for i in range(k1, k2+1):\n",
    "        search_space.append(common_alignment[:i])\n",
    "\n",
    "    return search_space\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACTCT\n"
     ]
    }
   ],
   "source": [
    "def tandem_transform_lcs(s: str, t: str, k1: int, k2: int, v: int):\n",
    "\n",
    "        # find best possible alignment between s and t longer than k1, uses greedy approach\n",
    "        common_alignment = lus(s, t, k1)\n",
    "        print(common_alignment)\n",
    "        \n",
    "        # align s and t to common prefix, get the left flanking and right flanking sequence\n",
    "        sl, sr, tl, tr = split_string(s, t, common_alignment)\n",
    "\n",
    "        # left kmer search space\n",
    "        search_space_l = get_search_space_left(sl, tl, k1, k2, common_alignment)\n",
    "\n",
    "        # right kmer search space\n",
    "        search_space_r = get_search_space_right(sr, tr, k1, k2, common_alignment)\n",
    "\n",
    "        # print(search_space_r)\n",
    "\n",
    "\n",
    "        # test all search space values and select the one that leads to highest global alignment score when applied\n",
    "\n",
    "        # apply transformation\n",
    "\n",
    "        # similarity score it with ENTIRE s and t string. if pass threshold with global alignemnt, dn this and return s and t transformed\n",
    "\n",
    "        # if not, apply transformation to s\n",
    "\n",
    "        # do this recursively with remaining sequence that is before transformation site, if left flanking as well as reamining sequence that is after the transformation site\n",
    "\n",
    "    \n",
    "    # you shoudl have a fully transformed tandem s string that when aligned with t, will produce a similarity score above the trheshold v\n",
    "\n",
    "\n",
    "# tandem_transform_lcs(\"ACCATCTT\",\n",
    "#                      \"TACCATCATC\",\n",
    "#                      2,\n",
    "#                      3,\n",
    "#                      6)\n",
    "\n",
    "# tandem_transform_lcs(\"GGACACTT\",\n",
    "#                      \"AAGGACT\",\n",
    "#                      2,\n",
    "#                      3,\n",
    "#                      0)\n",
    "\n",
    "tandem_transform_lcs(\"CCTAAAACTCTA\",\n",
    "                     \"CCTAACTCTCTA\",\n",
    "                     2,\n",
    "                     3,\n",
    "                     12)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
